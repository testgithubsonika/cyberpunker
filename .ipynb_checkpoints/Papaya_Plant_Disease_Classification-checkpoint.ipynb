{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sBVOH1v4mMzJ",
    "outputId": "2fc990ae-bd6e-4dcd-aac1-32f65396a5bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory '/mnt/data/papaya_dataset' created successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Define the path where you want to store the combined dataset\n",
    "base_dir = \"/mnt/data/papaya_dataset\"\n",
    "\n",
    "# Create the directory (if it doesn't exist)\n",
    "os.makedirs(base_dir, exist_ok=True)\n",
    "\n",
    "print(f\"Directory '{base_dir}' created successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m-----------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0mTraceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m files\n\u001b[0;32m      2\u001b[0m uploaded \u001b[38;5;241m=\u001b[39m files\u001b[38;5;241m.\u001b[39mupload()\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "from google.colab import files\n",
    "uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mpCylevBc7lV",
    "outputId": "4e886d9f-6d1b-40f8-e925-e95a03c6ac34",
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/content/Papaya_Ripe.zip'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m-----------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0mTraceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 24\u001b[0m\n\u001b[0;32m     21\u001b[0m     extract_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(base_dir, label)\n\u001b[0;32m     22\u001b[0m     os\u001b[38;5;241m.\u001b[39mmakedirs(extract_path, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 24\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mzipfile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mZipFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mzip_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m zip_ref:\n\u001b[0;32m     25\u001b[0m         zip_ref\u001b[38;5;241m.\u001b[39mextractall(extract_path)\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtraction complete. Images are labeled and organized.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\zipfile\\__init__.py:1323\u001b[0m, in \u001b[0;36mZipFile.__init__\u001b[1;34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps, metadata_encoding)\u001b[0m\n\u001b[0;32m   1321\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m   1322\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1323\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp \u001b[38;5;241m=\u001b[39m \u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilemode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1324\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[0;32m   1325\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m filemode \u001b[38;5;129;01min\u001b[39;00m modeDict:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/Papaya_Ripe.zip'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define dataset paths\n",
    "zip_files = {\n",
    "    \"/content/Papaya_Ripe.zip\": \"Ripe\",\n",
    "    \"/content/Papaya_Classification.zip\": \"Classification\",\n",
    "    \"/content/Papaya_Leaf.zip\": \"Leaf\"\n",
    "}\n",
    "\n",
    "# Create a directory to store the combined dataset\n",
    "base_dir = \"/mnt/data/papaya_dataset\"\n",
    "os.makedirs(base_dir, exist_ok=True)\n",
    "\n",
    "# Extract images and assign labels\n",
    "for zip_path, label in zip_files.items():\n",
    "    extract_path = os.path.join(base_dir, label)\n",
    "    os.makedirs(extract_path, exist_ok=True)\n",
    "\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_path)\n",
    "\n",
    "print(\"Extraction complete. Images are labeled and organized.\")\n",
    "\n",
    "# Splitting data into train, validation, and test sets\n",
    "data_dir = base_dir\n",
    "target_size = (150, 150)\n",
    "batch_size = 32\n",
    "\n",
    "# Data Augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.2  # 80-20 train-validation split\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=target_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "val_generator = train_datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=target_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "# Build a CNN Model\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(150, 150, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dense(len(zip_files), activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "epochs = 10\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=epochs\n",
    ")\n",
    "\n",
    "print(\"Model training complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iiRgw75lc7f9",
    "outputId": "04107e9f-28a5-49a4-9901-a63c6c2fce3c"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.listdir(base_dir))  # Check class folders\n",
    "for category in os.listdir(base_dir):\n",
    "    print(f\"{category}: {len(os.listdir(os.path.join(base_dir, category)))} images\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BySy-8Nyc7ds"
   },
   "outputs": [],
   "source": [
    "image_files = [f for f in os.listdir(category_path) if f.lower().endswith(('png', 'jpg', 'jpeg', 'bmp', 'gif'))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SX80tVfdc7Vd",
    "outputId": "e06e86d6-3d26-4d17-f737-2add6efa83d5"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "base_dir = \"/mnt/data/papaya_dataset\"\n",
    "\n",
    "for category in os.listdir(base_dir):\n",
    "    category_path = os.path.join(base_dir, category)\n",
    "    print(f\"\\nðŸ”¹ Checking category: {category}\")\n",
    "\n",
    "    if os.path.isdir(category_path):\n",
    "        sub_items = os.listdir(category_path)\n",
    "        print(f\"  Contains {len(sub_items)} items\")\n",
    "        print(\"  Sample items:\", sub_items[:5])  # Show first 5 items\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 592
    },
    "id": "vGKn8Bqt48Tj",
    "outputId": "ef31122c-12f2-4fae-947d-b1828b5e285a"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from PIL import Image\n",
    "\n",
    "# Define dataset path\n",
    "base_dir = \"/mnt/data/papaya_dataset\"\n",
    "categories = [\"Classification\", \"Ripe\", \"Leaf\"]\n",
    "\n",
    "# Create a dictionary to store image paths per category\n",
    "category_images = {}\n",
    "\n",
    "for category in categories:\n",
    "    category_path = os.path.join(base_dir, category)\n",
    "    image_files = []\n",
    "\n",
    "    # Walk through directories to find images\n",
    "    for root, _, files in os.walk(category_path):\n",
    "        for file in files:\n",
    "            if file.lower().endswith(('png', 'jpg', 'jpeg', 'bmp', 'gif')):\n",
    "                image_files.append(os.path.join(root, file))\n",
    "\n",
    "    # Store images (if available)\n",
    "    if image_files:\n",
    "        category_images[category] = image_files\n",
    "\n",
    "# Check if we found images\n",
    "if not category_images:\n",
    "    print(\"No images found in any category.\")\n",
    "else:\n",
    "    # Define the number of images per category to display\n",
    "    images_per_category = 5\n",
    "\n",
    "    # Create a subplot for each category\n",
    "    fig, axes = plt.subplots(len(category_images), images_per_category, figsize=(15, 5 * len(category_images)))\n",
    "\n",
    "    # Ensure axes are iterable for a single category case\n",
    "    if len(category_images) == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    for ax_row, (category, images) in zip(axes, category_images.items()):\n",
    "        selected_images = random.sample(images, min(images_per_category, len(images)))\n",
    "\n",
    "        for ax, img_path in zip(ax_row, selected_images):\n",
    "            img = Image.open(img_path)\n",
    "            ax.imshow(img)\n",
    "            ax.set_title(category)\n",
    "            ax.axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qUp6fy8sc7Nh",
    "outputId": "084ce166-dc8f-4aed-ea69-3e61abe263bd"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Define dataset path\n",
    "base_dir = \"/mnt/data/papaya_dataset\"\n",
    "\n",
    "# Define batch size and image size\n",
    "batch_size = 32\n",
    "img_height = 224\n",
    "img_width = 224\n",
    "\n",
    "# Create ImageDataGenerator for training (with augmentation)\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0 / 255.0,  # Normalize pixel values\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.2  # Use 20% of the data for validation\n",
    ")\n",
    "\n",
    "# Load training data\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    base_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"categorical\",  # Use 'binary' if only 2 classes\n",
    "    subset=\"training\"\n",
    ")\n",
    "\n",
    "# Load validation data\n",
    "val_generator = train_datagen.flow_from_directory(\n",
    "    base_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"categorical\",\n",
    "    subset=\"validation\"\n",
    ")\n",
    "\n",
    "# Get class indices (to verify labels)\n",
    "print(\"Class labels:\", train_generator.class_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 466
    },
    "id": "zmcvuaQPc7Kv",
    "outputId": "ca7d9c18-1cc2-44d8-ccd0-b5835cf286e6"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "# Define CNN model\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation=\"relu\", input_shape=(img_height, img_width, 3)),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Conv2D(64, (3, 3), activation=\"relu\"),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Conv2D(128, (3, 3), activation=\"relu\"),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Flatten(),\n",
    "    Dense(128, activation=\"relu\"),\n",
    "    Dropout(0.5),  # Prevent overfitting\n",
    "    Dense(len(train_generator.class_indices), activation=\"softmax\")  # Output layer\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=\"adam\",\n",
    "              loss=\"categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "# Model summary\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pkaCBi1zrTwB",
    "outputId": "f0b77d3f-0dd4-4fbc-baab-958a997e435f"
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "epochs = 10  # Increase for better results\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=epochs\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZfXyWuP8rVr-",
    "outputId": "41d92d6d-6774-4825-bfaa-1c21ba7442e3"
   },
   "outputs": [],
   "source": [
    "# Evaluate model on validation data\n",
    "loss, accuracy = model.evaluate(val_generator)\n",
    "print(f\"Validation Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Save model for future use\n",
    "model.save(\"/mnt/data/papaya_model.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "otv5AfJIrXU6",
    "outputId": "83b4e90e-f32e-42c8-d75a-0d78e9dceb37"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "\n",
    "# Load pre-trained MobileNetV2\n",
    "base_model = MobileNetV2(input_shape=(img_height, img_width, 3), include_top=False, weights=\"imagenet\")\n",
    "\n",
    "# Freeze base layers\n",
    "base_model.trainable = False\n",
    "\n",
    "# Add custom layers\n",
    "model = Sequential([\n",
    "    base_model,\n",
    "    GlobalAveragePooling2D(),\n",
    "    Dense(128, activation=\"relu\"),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(train_generator.class_indices), activation=\"softmax\")\n",
    "])\n",
    "\n",
    "# Compile and train (same steps as before)\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "model.fit(train_generator, validation_data=val_generator, epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XJH9mUJxrXRR",
    "outputId": "a901d799-1313-4c12-c644-b57058afa2af"
   },
   "outputs": [],
   "source": [
    "# Evaluate model on validation data\n",
    "loss, accuracy = model.evaluate(val_generator)\n",
    "print(f\"Validation Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Save model for future use\n",
    "model.save(\"/mnt/data/papaya_model.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wt_hrpoxrXOR"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gyBPgzc-rXMV"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jqx-zqnnrXKD"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0iCDkujWrXIE"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nNLyo27RrXFy"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ONkWfdusrXDO"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
